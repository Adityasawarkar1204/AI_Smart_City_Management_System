{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90a62391",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ab45750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af85ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "\n",
    "raw_path = \"C:/Users/user/Desktop/main/AI_Smart_City/data\"\n",
    "cleaned_path = \"C:/Users/user/Desktop/main/AI_Smart_City/cleaned\"\n",
    "\n",
    "os.makedirs(cleaned_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAFFIC DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Traffic Dataset...\n",
      "Shape before cleaning: (48204, 9)\n",
      "  holiday    temp  rain_1h  snow_1h  clouds_all weather_main  \\\n",
      "0     NaN  288.28      0.0      0.0          40       Clouds   \n",
      "1     NaN  289.36      0.0      0.0          75       Clouds   \n",
      "2     NaN  289.58      0.0      0.0          90       Clouds   \n",
      "3     NaN  290.13      0.0      0.0          90       Clouds   \n",
      "4     NaN  291.14      0.0      0.0          75       Clouds   \n",
      "\n",
      "  weather_description            date_time  traffic_volume  \n",
      "0    scattered clouds  2012-10-02 09:00:00            5545  \n",
      "1       broken clouds  2012-10-02 10:00:00            4516  \n",
      "2     overcast clouds  2012-10-02 11:00:00            4767  \n",
      "3     overcast clouds  2012-10-02 12:00:00            5026  \n",
      "4       broken clouds  2012-10-02 13:00:00            4918  \n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Traffic Dataset...\")\n",
    "traffic = pd.read_csv(os.path.join(raw_path, \"C:/Users/user/Desktop/main/AI_Smart_City/data/Metro_Interstate_Traffic_Volume.csv\"))\n",
    "\n",
    "print(\"Shape before cleaning:\", traffic.shape)\n",
    "print(traffic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = traffic.dropna(subset=['date_time', 'traffic_volume'])\n",
    "traffic = traffic.fillna(traffic.median(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic['date_time'] = pd.to_datetime(traffic['date_time'], errors='coerce')\n",
    "traffic = traffic.dropna(subset=['date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = traffic.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers removed using IQR method\n",
      " Shape after cleaning: (44651, 9)\n"
     ]
    }
   ],
   "source": [
    "# --- Remove outliers using IQR ---\n",
    "num_cols = traffic.select_dtypes(include=np.number).columns\n",
    "\n",
    "Q1 = traffic[num_cols].quantile(0.25)\n",
    "Q3 = traffic[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Keep only rows within 1.5 * IQR\n",
    "traffic = traffic[~((traffic[num_cols] < (Q1 - 1.5 * IQR)) | (traffic[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "print(\"Outliers removed using IQR method\")\n",
    "print(\" Shape after cleaning:\", traffic.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bde276ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b26453b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved  traffic_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_path = os.path.join(cleaned_path, \"traffic_cleaned.csv\")\n",
    "traffic.to_csv(output_path, index=False)\n",
    "print(\" Saved  traffic_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32c499f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIR QUALITY DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "522c8177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading Air Quality Dataset...\n",
      " Shape before cleaning: (9471, 17)\n",
      "        Date      Time  CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  \\\n",
      "0  3/10/2004  18:00:00     2.6       1360.0     150.0      11.9   \n",
      "1  3/10/2004  19:00:00     2.0       1292.0     112.0       9.4   \n",
      "2  3/10/2004  20:00:00     2.2       1402.0      88.0       9.0   \n",
      "3  3/10/2004  21:00:00     2.2       1376.0      80.0       9.2   \n",
      "4  3/10/2004  22:00:00     1.6       1272.0      51.0       6.5   \n",
      "\n",
      "   PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)  \\\n",
      "0         1046.0    166.0        1056.0    113.0        1692.0       1268.0   \n",
      "1          955.0    103.0        1174.0     92.0        1559.0        972.0   \n",
      "2          939.0    131.0        1140.0    114.0        1555.0       1074.0   \n",
      "3          948.0    172.0        1092.0    122.0        1584.0       1203.0   \n",
      "4          836.0    131.0        1205.0    116.0        1490.0       1110.0   \n",
      "\n",
      "      T    RH      AH  Unnamed: 15  Unnamed: 16  \n",
      "0  13.6  48.9  0.7578          NaN          NaN  \n",
      "1  13.3  47.7  0.7255          NaN          NaN  \n",
      "2  11.9  54.0  0.7502          NaN          NaN  \n",
      "3  11.0  60.0  0.7867          NaN          NaN  \n",
      "4  11.2  59.6  0.7888          NaN          NaN  \n"
     ]
    }
   ],
   "source": [
    "print(\" Loading Air Quality Dataset...\")\n",
    "aqi = pd.read_csv(os.path.join(raw_path, \"AirQualityUCI.csv\"))\n",
    "\n",
    "print(\" Shape before cleaning:\", aqi.shape)\n",
    "print(aqi.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "370e0c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "45a4ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi = aqi.fillna(aqi.median(numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8cd8b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "06c90afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi = aqi.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "23c44aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove outliers using IQR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "803532b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Outliers removed using IQR method\n",
      " Shape after cleaning: (5267, 17)\n"
     ]
    }
   ],
   "source": [
    "# --- Remove outliers using IQR (only for numeric columns) ---\n",
    "num_cols = aqi.select_dtypes(include=['number']).columns\n",
    "\n",
    "Q1 = aqi[num_cols].quantile(0.25)\n",
    "Q3 = aqi[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Keep only rows within 1.5 * IQR range for numeric columns\n",
    "aqi = aqi[~((aqi[num_cols] < (Q1 - 1.5 * IQR)) | (aqi[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "print(\" Outliers removed using IQR method\")\n",
    "print(\" Shape after cleaning:\", aqi.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4701248e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Shape after cleaning: (5267, 17)\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ Shape after cleaning:\", aqi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "190303c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "feb6b711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved ‚Üí air_quality_cleaned.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aqi.to_csv(os.path.join(cleaned_path, \"air_quality_cleaned.csv\"), index=False)\n",
    "print(\" Saved ‚Üí air_quality_cleaned.csv\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9f89e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENERGY CONSUMPTION DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f562a604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Loading Energy Dataset...\n",
      "‚úÖ Shape before cleaning: (2075259, 9)\n",
      "         Date      Time Global_active_power Global_reactive_power  Voltage  \\\n",
      "0  16/12/2006  17:24:00               4.216                 0.418  234.840   \n",
      "1  16/12/2006  17:25:00               5.360                 0.436  233.630   \n",
      "2  16/12/2006  17:26:00               5.374                 0.498  233.290   \n",
      "3  16/12/2006  17:27:00               5.388                 0.502  233.740   \n",
      "4  16/12/2006  17:28:00               3.666                 0.528  235.680   \n",
      "\n",
      "  Global_intensity Sub_metering_1 Sub_metering_2  Sub_metering_3  \n",
      "0           18.400          0.000          1.000            17.0  \n",
      "1           23.000          0.000          1.000            16.0  \n",
      "2           23.000          0.000          2.000            17.0  \n",
      "3           23.000          0.000          1.000            17.0  \n",
      "4           15.800          0.000          1.000            17.0  \n"
     ]
    }
   ],
   "source": [
    "print( Loading Energy Dataset...\")\n",
    "\n",
    "energy_file = os.path.join(raw_path, \"household_power_consumption.txt\")\n",
    "\n",
    "if not os.path.exists(energy_file):\n",
    "    print(\"‚ö†Ô∏è File not found:\", energy_file)\n",
    "else:\n",
    "    energy = pd.read_csv(energy_file, sep=';', low_memory=False)\n",
    "\n",
    "    print(\"‚úÖ Shape before cleaning:\", energy.shape)\n",
    "    print(energy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "32acbe41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Shape before cleaning: (2075259, 9)\n",
      "         Date      Time Global_active_power Global_reactive_power  Voltage  \\\n",
      "0  16/12/2006  17:24:00               4.216                 0.418  234.840   \n",
      "1  16/12/2006  17:25:00               5.360                 0.436  233.630   \n",
      "2  16/12/2006  17:26:00               5.374                 0.498  233.290   \n",
      "3  16/12/2006  17:27:00               5.388                 0.502  233.740   \n",
      "4  16/12/2006  17:28:00               3.666                 0.528  235.680   \n",
      "\n",
      "  Global_intensity Sub_metering_1 Sub_metering_2  Sub_metering_3  \n",
      "0           18.400          0.000          1.000            17.0  \n",
      "1           23.000          0.000          1.000            16.0  \n",
      "2           23.000          0.000          2.000            17.0  \n",
      "3           23.000          0.000          1.000            17.0  \n",
      "4           15.800          0.000          1.000            17.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ Shape before cleaning:\", energy.shape)\n",
    "print(energy.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee03b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1901ce0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18240\\1265377183.py:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  energy = energy.fillna(method='ffill').fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "energy = energy.fillna(method='ffill').fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "48086660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Convert date column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ed65823",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = [col for col in energy.columns if 'date' in col.lower() or 'time' in col.lower()]\n",
    "if date_cols:\n",
    "    energy[date_cols[0]] = pd.to_datetime(energy[date_cols[0]], errors='coerce')\n",
    "    energy = energy.dropna(subset=[date_cols[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "39ebb05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = [col for col in energy.columns if 'date' in col.lower() or 'time' in col.lower()]\n",
    "if date_cols:\n",
    "    energy[date_cols[0]] = pd.to_datetime(energy[date_cols[0]], errors='coerce')\n",
    "    energy = energy.dropna(subset=[date_cols[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dcc350",
   "metadata": {},
   "outputs": [],
   "source": [
    "sssssssssssss\n",
    "energy = energy.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ff48d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
